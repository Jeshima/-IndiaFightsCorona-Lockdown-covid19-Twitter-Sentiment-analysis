{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>full_text</th>\n",
       "      <th>sent_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>whi wait get fine govern take care wear mask m...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>start monday delhi govern gave relax lockdown ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>not meme just inform lockdown look like</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>with lockdown focu reviv economi howev team vi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>hello guy video get look sonam kapoor celebr i...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          full_text  sent_score\n",
       "0           0  whi wait get fine govern take care wear mask m...          -1\n",
       "1           1  start monday delhi govern gave relax lockdown ...          -1\n",
       "2           2            not meme just inform lockdown look like          -1\n",
       "3           3  with lockdown focu reviv economi howev team vi...          -1\n",
       "4           4  hello guy video get look sonam kapoor celebr i...          -1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = 'ifc_clean_tweets.csv'\n",
    "my_df = pd.read_csv(csv)\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1748 entries, 0 to 1747\n",
      "Data columns (total 3 columns):\n",
      "Unnamed: 0    1748 non-null int64\n",
      "full_text     1748 non-null object\n",
      "sent_score    1748 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 41.1+ KB\n"
     ]
    }
   ],
   "source": [
    "my_df.dropna(inplace=True)\n",
    "my_df.reset_index(drop=True,inplace=True)\n",
    "my_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = my_df.full_text\n",
    "y = my_df.sent_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "SEED = 2000\n",
    "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.02, random_state=SEED)\n",
    "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has total 1713 entries with 13.25% negative, 54.17% positive\n",
      "Validation set has total 35.294117647058826 entries with 5.88% negative, 35.29% positive\n",
      "Test set has total 55.55555555555556 entries with 5.56% negative, 55.56% positive\n"
     ]
    }
   ],
   "source": [
    "print (\"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_train),\n",
    "                                                                             (len(x_train[y_train == 0]) / (len(x_train)*1.))*100,\n",
    "                                                                            (len(x_train[y_train == 1]) / (len(x_train)*1.))*100))\n",
    "print (\"Validation set has total {2} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_validation),\n",
    "                                                                             (len(x_validation[y_validation == 0]) / (len(x_validation)*1.))*100,\n",
    "                                                                            (len(x_validation[y_validation == 1]) / (len(x_validation)*1.))*100))\n",
    "print (\"Test set has total {2} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_test),\n",
    "                                                                             (len(x_test[y_test == 0]) / (len(x_test)*1.))*100,\n",
    "                                                                            (len(x_test[y_test == 1]) / (len(x_test)*1.))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0,\n",
       "                max_features=100000, min_df=1, ngram_range=(1, 3), norm='l2',\n",
       "                preprocessor=None, smooth_idf=True, stop_words=None,\n",
       "                strip_accents=None, sublinear_tf=False,\n",
       "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvec1 = TfidfVectorizer(max_features=100000,ngram_range=(1, 3))\n",
    "tvec1.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tfidf = tvec1.transform(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation_tfidf = tvec1.transform(x_validation).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.54 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4117647058823529"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_validation_tfidf, y_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182720373613543"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X_data, y_data, batch_size):\n",
    "    samples_per_epoch = X_data.shape[0]\n",
    "    number_of_batches = samples_per_epoch/batch_size\n",
    "    counter=0\n",
    "    index = np.arange(np.shape(y_data)[0])\n",
    "    while 1:\n",
    "        index_batch = index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X_data[index_batch,:].toarray()\n",
    "        y_batch = y_data[y_data.index[index_batch]]\n",
    "        counter += 1\n",
    "        yield X_batch,y_batch\n",
    "        if (counter > number_of_batches):\n",
    "            counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "54/53 [==============================] - 3s 59ms/step - loss: 0.6147 - accuracy: 0.1524 - val_loss: 0.3024 - val_accuracy: 0.0588\n",
      "Epoch 2/5\n",
      "54/53 [==============================] - 3s 48ms/step - loss: 0.2138 - accuracy: 0.2154 - val_loss: -0.1777 - val_accuracy: 0.2353\n",
      "Epoch 3/5\n",
      "54/53 [==============================] - 3s 48ms/step - loss: -0.4283 - accuracy: 0.4081 - val_loss: -0.5778 - val_accuracy: 0.2353\n",
      "Epoch 4/5\n",
      "54/53 [==============================] - 3s 51ms/step - loss: -1.2951 - accuracy: 0.5797 - val_loss: -1.2136 - val_accuracy: 0.2353\n",
      "Epoch 5/5\n",
      "54/53 [==============================] - 3s 48ms/step - loss: -2.3761 - accuracy: 0.6054 - val_loss: -2.1354 - val_accuracy: 0.2353\n",
      "Wall time: 14.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x238e0ce9320>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=35453))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator=batch_generator(x_train_tfidf, y_train, 32),\n",
    "                    epochs=5, validation_data=(x_validation_tfidf, y_validation),\n",
    "                    steps_per_epoch=x_train_tfidf.shape[0]/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.preprocessing import Normalizer\n",
    "norm = Normalizer().fit(x_train_tfidf)\n",
    "x_train_tfidf_norm = norm.transform(x_train_tfidf)\n",
    "x_validation_tfidf_norm = norm.transform(x_validation_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "54/53 [==============================] - 3s 60ms/step - loss: 0.6160 - accuracy: 0.1559 - val_loss: 0.3130 - val_accuracy: 0.1176\n",
      "Epoch 2/5\n",
      "54/53 [==============================] - 3s 49ms/step - loss: 0.2203 - accuracy: 0.2195 - val_loss: -0.1562 - val_accuracy: 0.2353\n",
      "Epoch 3/5\n",
      "54/53 [==============================] - 3s 48ms/step - loss: -0.4168 - accuracy: 0.4203 - val_loss: -0.5467 - val_accuracy: 0.2353\n",
      "Epoch 4/5\n",
      "54/53 [==============================] - 3s 52ms/step - loss: -1.2744 - accuracy: 0.5849 - val_loss: -1.1721 - val_accuracy: 0.2353\n",
      "Epoch 5/5\n",
      "54/53 [==============================] - 3s 52ms/step - loss: -2.3373 - accuracy: 0.6095 - val_loss: -2.0762 - val_accuracy: 0.2353\n",
      "Wall time: 14.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x238e22ed0f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_n = Sequential()\n",
    "model_n.add(Dense(64, activation='relu', input_dim=35453))\n",
    "model_n.add(Dense(1, activation='sigmoid'))\n",
    "model_n.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_n.fit_generator(generator=batch_generator(x_train_tfidf_norm, y_train, 32),\n",
    "                    epochs=5, validation_data=(x_validation_tfidf_norm, y_validation),\n",
    "                    steps_per_epoch=x_train_tfidf_norm.shape[0]/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "54/53 [==============================] - 3s 58ms/step - loss: 0.6235 - accuracy: 0.1500 - val_loss: 0.3362 - val_accuracy: 0.0588\n",
      "Epoch 2/5\n",
      "54/53 [==============================] - 3s 48ms/step - loss: 0.2855 - accuracy: 0.1874 - val_loss: -0.1106 - val_accuracy: 0.2353\n",
      "Epoch 3/5\n",
      "54/53 [==============================] - 3s 50ms/step - loss: -0.2496 - accuracy: 0.3205 - val_loss: -0.4796 - val_accuracy: 0.2353\n",
      "Epoch 4/5\n",
      "54/53 [==============================] - 3s 51ms/step - loss: -1.0142 - accuracy: 0.5201 - val_loss: -1.0135 - val_accuracy: 0.2353\n",
      "Epoch 5/5\n",
      "54/53 [==============================] - 3s 49ms/step - loss: -1.9569 - accuracy: 0.5692 - val_loss: -1.8125 - val_accuracy: 0.2353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x238e3686160>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(64, activation='relu', input_dim=35453))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.fit_generator(generator=batch_generator(x_train_tfidf, y_train, 32),\n",
    "                    epochs=5, validation_data=(x_validation_tfidf, y_validation),\n",
    "                    steps_per_epoch=x_train_tfidf.shape[0]/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator_shuffle(X_data, y_data, batch_size):\n",
    "    samples_per_epoch = X_data.shape[0]\n",
    "    number_of_batches = samples_per_epoch/batch_size\n",
    "    counter=0\n",
    "    index = np.arange(np.shape(y_data)[0])\n",
    "    np.random.shuffle(index)\n",
    "    while 1:\n",
    "        index_batch = index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X_data[index_batch,:].toarray()\n",
    "        y_batch = y_data[y_data.index[index_batch]]\n",
    "        counter += 1\n",
    "        yield X_batch,y_batch\n",
    "        if (counter > number_of_batches):\n",
    "            np.random.shuffle(index)\n",
    "            counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "54/53 [==============================] - 3s 57ms/step - loss: 0.6208 - accuracy: 0.1635 - val_loss: 0.3312 - val_accuracy: 0.0588\n",
      "Epoch 2/5\n",
      "54/53 [==============================] - 3s 53ms/step - loss: 0.2567 - accuracy: 0.2055 - val_loss: -0.1059 - val_accuracy: 0.2353\n",
      "Epoch 3/5\n",
      "54/53 [==============================] - 3s 48ms/step - loss: -0.3377 - accuracy: 0.4069 - val_loss: -0.4910 - val_accuracy: 0.2353\n",
      "Epoch 4/5\n",
      "54/53 [==============================] - 3s 49ms/step - loss: -1.1672 - accuracy: 0.5890 - val_loss: -1.0619 - val_accuracy: 0.2353\n",
      "Epoch 5/5\n",
      "54/53 [==============================] - 3s 50ms/step - loss: -2.1767 - accuracy: 0.6147 - val_loss: -1.9627 - val_accuracy: 0.2353\n",
      "Wall time: 14.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x238e5902198>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "model_s = Sequential()\n",
    "model_s.add(Dense(64, activation='relu', input_dim=35453))\n",
    "model_s.add(Dense(1, activation='sigmoid'))\n",
    "model_s.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_s.fit_generator(generator=batch_generator_shuffle(x_train_tfidf, y_train, 32),\n",
    "                    epochs=5, validation_data=(x_validation_tfidf, y_validation),\n",
    "                    steps_per_epoch=x_train_tfidf.shape[0]/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "54/53 [==============================] - 3s 58ms/step - loss: 0.6359 - accuracy: 0.1535 - val_loss: 0.3891 - val_accuracy: 0.0588\n",
      "Epoch 2/5\n",
      "54/53 [==============================] - 3s 51ms/step - loss: 0.3397 - accuracy: 0.1903 - val_loss: -0.0248 - val_accuracy: 0.2353\n",
      "Epoch 3/5\n",
      "54/53 [==============================] - 3s 48ms/step - loss: -0.1365 - accuracy: 0.3252 - val_loss: -0.3488 - val_accuracy: 0.2353\n",
      "Epoch 4/5\n",
      "54/53 [==============================] - 3s 49ms/step - loss: -0.8176 - accuracy: 0.5552 - val_loss: -0.7887 - val_accuracy: 0.2353\n",
      "Epoch 5/5\n",
      "54/53 [==============================] - 3s 49ms/step - loss: -1.6615 - accuracy: 0.5943 - val_loss: -1.4607 - val_accuracy: 0.2353\n",
      "Wall time: 14.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x238e5faa5c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "model_s_1 = Sequential()\n",
    "model_s_1.add(Dense(64, activation='relu', input_dim=35453))\n",
    "model_s_1.add(Dropout(0.2))\n",
    "model_s_1.add(Dense(1, activation='sigmoid'))\n",
    "model_s_1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_s_1.fit_generator(generator=batch_generator_shuffle(x_train_tfidf, y_train, 32),\n",
    "                    epochs=5, validation_data=(x_validation_tfidf, y_validation),\n",
    "                    steps_per_epoch=x_train_tfidf.shape[0]/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "54/53 [==============================] - 3s 58ms/step - loss: 0.3987 - accuracy: 0.1570 - val_loss: -0.7945 - val_accuracy: 0.2353\n",
      "Epoch 2/5\n",
      "54/53 [==============================] - 3s 51ms/step - loss: -2.1261 - accuracy: 0.3847 - val_loss: -3.2655 - val_accuracy: 0.2353\n",
      "Epoch 3/5\n",
      "54/53 [==============================] - 3s 54ms/step - loss: -9.8428 - accuracy: 0.5184 - val_loss: -10.6643 - val_accuracy: 0.1765\n",
      "Epoch 4/5\n",
      "54/53 [==============================] - 3s 50ms/step - loss: -23.4169 - accuracy: 0.5085 - val_loss: -22.3368 - val_accuracy: 0.2353\n",
      "Epoch 5/5\n",
      "54/53 [==============================] - 3s 48ms/step - loss: -44.8907 - accuracy: 0.5020 - val_loss: -39.1998 - val_accuracy: 0.2353\n",
      "Wall time: 14.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x238e65d3320>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "import keras\n",
    "custom_adam = keras.optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "model_testing_2 = Sequential()\n",
    "model_testing_2.add(Dense(64, activation='relu', input_dim=35453))\n",
    "model_testing_2.add(Dense(1, activation='sigmoid'))\n",
    "model_testing_2.compile(optimizer=custom_adam,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_testing_2.fit_generator(generator=batch_generator_shuffle(x_train_tfidf, y_train, 32),\n",
    "                    epochs=5, validation_data=(x_validation_tfidf, y_validation),\n",
    "                    steps_per_epoch=x_train_tfidf.shape[0]/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "54/53 [==============================] - 3s 56ms/step - loss: 0.1708 - accuracy: 0.2037 - val_loss: -1.5514 - val_accuracy: 0.2941\n",
      "Epoch 2/5\n",
      "54/53 [==============================] - 3s 47ms/step - loss: -8.1149 - accuracy: 0.4437 - val_loss: -11.6145 - val_accuracy: 0.2353\n",
      "Epoch 3/5\n",
      "54/53 [==============================] - 3s 48ms/step - loss: -37.4788 - accuracy: 0.4682 - val_loss: -42.2377 - val_accuracy: 0.2353\n",
      "Epoch 4/5\n",
      "54/53 [==============================] - 3s 51ms/step - loss: -94.7732 - accuracy: 0.4565 - val_loss: -84.0767 - val_accuracy: 0.2353\n",
      "Epoch 5/5\n",
      "54/53 [==============================] - 3s 49ms/step - loss: -181.8308 - accuracy: 0.4892 - val_loss: -155.4153 - val_accuracy: 0.2353\n",
      "Wall time: 14.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x238e6b8f3c8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "custom_adam = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "model_testing_3 = Sequential()\n",
    "model_testing_3.add(Dense(64, activation='relu', input_dim=35453))\n",
    "model_testing_3.add(Dense(1, activation='sigmoid'))\n",
    "model_testing_3.compile(optimizer=custom_adam,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_testing_3.fit_generator(generator=batch_generator_shuffle(x_train_tfidf, y_train, 32),\n",
    "                    epochs=5, validation_data=(x_validation_tfidf, y_validation),\n",
    "                    steps_per_epoch=x_train_tfidf.shape[0]/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "54/53 [==============================] - 3s 55ms/step - loss: -6.8633 - accuracy: 0.2890 - val_loss: -41.6529 - val_accuracy: 0.2941\n",
      "Epoch 2/5\n",
      "54/53 [==============================] - 3s 48ms/step - loss: -414.8772 - accuracy: 0.3701 - val_loss: -618.9533 - val_accuracy: 0.2941\n",
      "Epoch 3/5\n",
      "54/53 [==============================] - 3s 51ms/step - loss: -2348.4646 - accuracy: 0.4326 - val_loss: -2505.2078 - val_accuracy: 0.1765\n",
      "Epoch 4/5\n",
      "54/53 [==============================] - 3s 51ms/step - loss: -6726.8036 - accuracy: 0.4402 - val_loss: -5494.8032 - val_accuracy: 0.2353\n",
      "Epoch 5/5\n",
      "54/53 [==============================] - 3s 51ms/step - loss: -14023.1971 - accuracy: 0.4752 - val_loss: -10935.0859 - val_accuracy: 0.2353\n",
      "Wall time: 14.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x238e6d3e208>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "custom_adam = keras.optimizers.Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "model_testing_4 = Sequential()\n",
    "model_testing_4.add(Dense(64, activation='relu', input_dim=35453))\n",
    "model_testing_4.add(Dense(1, activation='sigmoid'))\n",
    "model_testing_4.compile(optimizer=custom_adam,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_testing_4.fit_generator(generator=batch_generator_shuffle(x_train_tfidf, y_train, 32),\n",
    "                    epochs=5, validation_data=(x_validation_tfidf, y_validation),\n",
    "                    steps_per_epoch=x_train_tfidf.shape[0]/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "54/53 [==============================] - 3s 56ms/step - loss: 0.6614 - accuracy: 0.1956 - val_loss: 0.5450 - val_accuracy: 0.1176\n",
      "Epoch 2/5\n",
      "54/53 [==============================] - 3s 48ms/step - loss: 0.5158 - accuracy: 0.2055 - val_loss: 0.3626 - val_accuracy: 0.1765\n",
      "Epoch 3/5\n",
      "54/53 [==============================] - 3s 48ms/step - loss: 0.2834 - accuracy: 0.3287 - val_loss: 0.1796 - val_accuracy: 0.2353\n",
      "Epoch 4/5\n",
      "54/53 [==============================] - 3s 50ms/step - loss: -0.0340 - accuracy: 0.5575 - val_loss: 0.0061 - val_accuracy: 0.2353\n",
      "Epoch 5/5\n",
      "54/53 [==============================] - 3s 49ms/step - loss: -0.3958 - accuracy: 0.6270 - val_loss: -0.1634 - val_accuracy: 0.2353\n",
      "Wall time: 14 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x238918d56a0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "custom_adam = keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "model_testing_5 = Sequential()\n",
    "model_testing_5.add(Dense(64, activation='relu', input_dim=35453))\n",
    "model_testing_5.add(Dense(1, activation='sigmoid'))\n",
    "model_testing_5.compile(optimizer=custom_adam,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_testing_5.fit_generator(generator=batch_generator_shuffle(x_train_tfidf, y_train, 32),\n",
    "                    epochs=5, validation_data=(x_validation_tfidf, y_validation),\n",
    "                    steps_per_epoch=x_train_tfidf.shape[0]/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "54/53 [==============================] - 5s 89ms/step - loss: 0.5844 - accuracy: 0.1705 - val_loss: 0.1418 - val_accuracy: 0.1765\n",
      "Epoch 2/5\n",
      "54/53 [==============================] - 5s 83ms/step - loss: 0.0229 - accuracy: 0.2353 - val_loss: -0.3740 - val_accuracy: 0.2353\n",
      "Epoch 3/5\n",
      "54/53 [==============================] - 4s 83ms/step - loss: -0.9851 - accuracy: 0.5231 - val_loss: -1.1358 - val_accuracy: 0.2353\n",
      "Epoch 4/5\n",
      "54/53 [==============================] - 4s 82ms/step - loss: -2.4874 - accuracy: 0.5750 - val_loss: -2.4438 - val_accuracy: 0.2353\n",
      "Epoch 5/5\n",
      "54/53 [==============================] - 5s 85ms/step - loss: -4.5941 - accuracy: 0.5750 - val_loss: -4.1981 - val_accuracy: 0.2353\n",
      "Wall time: 23.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23891e630f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "model_s_2 = Sequential()\n",
    "model_s_2.add(Dense(128, activation='relu', input_dim=35453))\n",
    "model_s_2.add(Dense(1, activation='sigmoid'))\n",
    "model_s_2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_s_2.fit_generator(generator=batch_generator_shuffle(x_train_tfidf, y_train, 32),\n",
    "                    epochs=5, validation_data=(x_validation_tfidf, y_validation),\n",
    "                    steps_per_epoch=x_train_tfidf.shape[0]/32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference--- https://github.com/tthustla/twitter_sentiment_analysis_part9/blob/master/Capstone_part4-Copy7.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
